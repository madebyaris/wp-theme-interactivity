---
description: "Cursor 2.4 agent orchestration: native subagents, Agent Skills, adaptive effort delegation, parallel workflows, hierarchical task decomposition, and multi-agent coordination. Load this for complex multi-step tasks."
alwaysApply: false
---

# Cursor 2.4 Agent Orchestration

Advanced patterns for working with Cursor 2.4's native subagents, Agent Skills system, and multi-agent coordination.

## Cursor 2.4 Architecture Overview

```
┌─────────────────────────────────────────────────────────────┐
│                    CURSOR 2.4 AGENT                         │
├─────────────────────────────────────────────────────────────┤
│  Main Agent                                                 │
│    ├── Built-in Subagents (automatic)                       │
│    │     ├── explore   → codebase search (fast model)       │
│    │     ├── bash      → shell commands (isolated output)   │
│    │     └── browser   → web automation (MCP-based)         │
│    │                                                        │
│    ├── Custom Subagents (.cursor/agents/)                   │
│    │     ├── verifier  → validate completed work            │
│    │     └── debugger  → error analysis                     │
│    │                                                        │
│    └── Context Sources                                      │
│          ├── Rules (.cursor/rules/) → always/glob-triggered │
│          ├── Skills (.cursor/skills/) → on-demand/slash cmd │
│          └── Semantic Index → meaning-based search          │
└─────────────────────────────────────────────────────────────┘
```

## Agent Transcripts Citation

When referencing past chats from agent transcripts:
- **Format**: `[Title](uuid)` — use a short title (≤6 words) and the parent uuid (exclude `.jsonl`)
- **Never cite subagent transcripts** — always use the parent uuid, not subagent IDs

## Opus 4.6 Max Planning and Communication

Operate with Opus 4.6 behavioral patterns — adaptive effort, self-critical, intellectually honest:

- **Adaptive effort**: Scale planning depth to task complexity. Don't create EPIC todos for a typo fix. Use full investigation for architecture changes.
- **Decision forks only**: Ask questions only when choices materially change security, data integrity, or core architecture.
- **Default-first**: For reversible choices, state the assumption once and proceed.
- **Concise updates**: Progress updates should be 1-2 sentences, high-signal only.
- **Tool-first execution**: Prefer targeted tool calls, batch when possible.
- **Self-review before delivery**: Challenge your own solutions. What would break? What edge case is missing?

## CRITICAL: Date-Aware Search Protocol

### Always Check Current Date First

**BEFORE any web search for tech stack, versions, or solutions:**

```
<think>
Current date: [extract from user_info, e.g., "February 2026"]
This date MUST be used in all version/tech queries.
</think>
```

**Correct search format:**
```
"Next.js latest stable version [current month] [current year]"
"React hooks documentation [current year]"
"shadcn-ui installation guide [current year]"
```

**NEVER hardcode specific version numbers in rules files** — they go stale in weeks. Always verify via WebSearch at query time.

**NEVER use template placeholders** — no `{version}`, `{date_year}`, `${variable}`, `[PLACEHOLDER]`. Always use concrete values.

**Strategic laziness**: Only search versions for NEW packages being added. Don't re-search versions for packages already in the project unless there's a version-related error.

---

## Auto Web-Search Error Recovery

### Persistent Error Escalation

After 3-4 failed attempts at the same error, stop trying variations and search:

```
<think>
Same error after [N] attempts. My internal knowledge is insufficient.
Escalating to web search.
</think>

// 1. Exact error
→ WebSearch(search_term="[exact error text] fix [framework] [year]")

// 2. Error type
→ WebSearch(search_term="[error type] [framework] common causes [year]")

// 3. Context-based
→ WebSearch(search_term="[what I was trying to do] [framework] tutorial [year]")

// 4. Official docs (if Context7 available)
→ user-context7-resolve-library-id(libraryName="[framework]")
→ user-context7-query-docs(libraryId="...", query="[error-related-topic]")
```

**Key**: Track errors by their core message. After 3-4 failures with the same signature, the threshold is reached — mandatory web search.

---

## Hierarchical Task Decomposition (Exhaustive-Level Only)

### EPIC-Based Todo Structure

For **Exhaustive-level** complex projects, use hierarchical task organization. Do NOT create EPIC structures for Instant/Light tasks.

```
TODO Structure:
├── EPIC0: Prerequisites (design systems, dependencies, setup)
│   ├── EPIC0.1: Install core dependencies
│   ├── EPIC0.2: Configure design system
│   └── EPIC0.3: Set up project structure
├── EPIC1: Feature A (Auth)
│   ├── EPIC1.1: Create auth pages
│   ├── EPIC1.2: Create auth API routes
│   └── EPIC1.3: Add auth middleware
├── EPIC2: Feature B (Dashboard)
│   ├── EPIC2.1: Create dashboard layout
│   └── EPIC2.2: Add dashboard widgets
└── EPIC3: Integration & Testing
    ├── EPIC3.1: Integration testing
    └── EPIC3.2: E2E testing
```

### Todo Creation Rules

1. **Prerequisites First**: Always create EPIC0 for setup/dependencies
2. **Feature Isolation**: Each major feature gets its own EPIC
3. **Sub-task Granularity**: Each sub-task should be testable independently
4. **Sequential Dependencies**: Mark which EPICs depend on others

### Example Todo for "Build an Auth System":

```
todos: [
  { id: "EPIC0", content: "Prerequisites: Install dependencies and configure project", status: "in_progress" },
  { id: "EPIC0.1", content: "Install Next.js, Tailwind, shadcn-ui, NextAuth", status: "pending" },
  { id: "EPIC0.2", content: "Configure Prisma with database schema", status: "pending" },
  { id: "EPIC1", content: "Auth UI: Build all authentication pages", status: "pending" },
  { id: "EPIC1.1", content: "Create login page with form validation", status: "pending" },
  { id: "EPIC1.2", content: "Create register page with form validation", status: "pending" },
  { id: "EPIC1.3", content: "Create forgot password flow", status: "pending" },
  { id: "EPIC2", content: "Auth API: Build backend authentication", status: "pending" },
  { id: "EPIC2.1", content: "Create NextAuth configuration with providers", status: "pending" },
  { id: "EPIC2.2", content: "Create API routes for auth operations", status: "pending" },
  { id: "EPIC2.3", content: "Add middleware for protected routes", status: "pending" },
  { id: "EPIC3", content: "Testing: Verify each component works", status: "pending" },
  { id: "EPIC3.1", content: "Test login flow end-to-end", status: "pending" },
  { id: "EPIC3.2", content: "Test registration flow end-to-end", status: "pending" }
]
```

### Per-File Verification

Test after each file, not after the whole feature:

```
After EACH file creation:
1. ReadLints(paths=["path/to/new/file"])
2. If UI component: Quick browser snapshot
3. If API route: Quick curl/fetch test
4. Mark sub-task complete only after file verified

After EACH EPIC completion:
1. Integration test for that EPIC only
2. Check for regressions in previous EPICs
3. Mark EPIC complete

After ALL EPICs:
1. Full system test
2. E2E testing
3. Mark project complete
```

---

## Minimal Questions Policy

Only ask when the decision is a **hard fork**:

- Security/auth flows, data deletion/migration, or major architectural changes.
- Irreversible choices with high cost to undo.

Otherwise:

- Choose a safe, reversible default.
- State the assumption once.
- Proceed and verify.

---

## Cursor 2.4 Native Subagents

Cursor 2.4 introduces **native subagents** - independent agents that handle discrete parts of tasks with their own context windows.

### Built-in Subagents (Automatic)

These subagents are used automatically by the agent when appropriate:

| Subagent | Purpose | Why It's a Subagent |
|----------|---------|---------------------|
| **explore** | Searches and analyzes codebases | Generates large intermediate output; uses fast model for parallel searches |
| **bash** | Runs series of shell commands | Command output is verbose; isolates logs from main context |
| **browser** | Controls browser via MCP tools | DOM snapshots are noisy; filters down to relevant results |

**You don't configure these** - they activate automatically based on task context.

### Custom Subagents

Define custom subagents in `.cursor/agents/` (project) or `~/.cursor/agents/` (user).

**File Format** (markdown with YAML frontmatter):

```markdown
---
name: security-auditor
description: Security specialist. Use when implementing auth, payments, or handling sensitive data.
model: fast
---

You are a security expert auditing code for vulnerabilities.

When invoked:
1. Identify security-sensitive code paths
2. Check for common vulnerabilities (injection, XSS, auth bypass)
3. Verify secrets are not hardcoded
4. Review input validation

Report findings by severity: Critical, High, Medium.
```

**Frontmatter Fields:**

| Field | Required | Description |
|-------|----------|-------------|
| `name` | No | Unique identifier (lowercase, hyphens). Defaults to filename. |
| `description` | No | When to use this subagent. Agent reads this to decide delegation. |
| `model` | No | `fast`, `inherit`, or specific model ID. Default: `inherit`. |
| `readonly` | No | If `true`, restricted write permissions. |
| `is_background` | No | If `true`, runs in background without blocking. |

### Invoking Custom Subagents

**Automatic**: Agent delegates based on task and description match.

**Explicit**: Use `/name` syntax in prompts:
```
> /verifier confirm the auth flow is complete
> /debugger investigate this error
```

### Task Tool (Different from Native Subagents)

The `Task` tool still exists but operates differently - it's for launching sub-agents programmatically:

```
→ Task(
    subagent_type="generalPurpose",  // or "explore"
    prompt="Check if authentication is already implemented",
    description="Check auth status",
    model="fast"
  )
```

**When to Use Task vs Native Subagents:**

| Use Case | Approach |
|----------|----------|
| Complex codebase exploration | Native `explore` (automatic) or Task with explore |
| Shell command sequences | Native `bash` (automatic) |
| Browser testing | Native `browser` (automatic) |
| Custom specialized work | Custom subagent in `.cursor/agents/` |
| Programmatic delegation | Task tool |

**Adaptive Effort + Subagent Delegation (Opus 4.6 Pattern):**

| Task Effort Level | Delegation Strategy |
|-------------------|---------------------|
| Instant / Light | Do it yourself — no subagent overhead |
| Deep | Use `model="fast"` subagents for investigation, do implementation yourself |
| Exhaustive | Parallel subagents for independent features, full model for complex work |

**Task Tool Best Practices:**
- Subagents start fresh — include ALL necessary context in prompt
- Use `model="fast"` for exploration and simple research (Instant/Light effort)
- Launch multiple Tasks in parallel for independent features
- Results are not visible to user — summarize in your response

---

### TodoWrite Tool - Task Management

Use `TodoWrite` for EPIC-based task tracking:

```
→ TodoWrite(
    todos=[
      { id: "EPIC0", content: "Setup: Install dependencies and configure project", status: "in_progress" },
      { id: "EPIC0.1", content: "Run npx create-next-app with TypeScript", status: "pending" },
      { id: "EPIC0.2", content: "Install and configure shadcn-ui", status: "pending" },
      { id: "EPIC1", content: "Feature: User Authentication", status: "pending" },
      { id: "EPIC1.1", content: "Create login page with form validation", status: "pending" },
      { id: "EPIC1.2", content: "Create register page", status: "pending" }
    ],
    merge=false  // Replace all todos
  )
```

**Updating Todo Status:**
```
→ TodoWrite(
    todos=[{ id: "EPIC0", status: "completed" }],
    merge=true  // Only update specified todos
  )
```

**When to Use TodoWrite (Deep/Exhaustive effort only):**
- Complex multi-step tasks (3+ steps)
- Tasks requiring careful planning
- User provides multiple tasks
- After receiving new instructions — capture as todos

**When NOT to Use (Instant/Light effort):**
- Single straightforward tasks
- Tasks completable in < 3 steps
- Purely conversational requests
- Simple fixes, renames, or one-file changes

---

### CreatePlan Tool - Plan Mode

Use `CreatePlan` in Plan Mode for structured planning:

```
→ CreatePlan(
    name="Authentication System",
    overview="Implement complete auth with NextAuth.js, including login, register, and protected routes",
    plan="# Implementation Plan\n\n## Phase 1: Setup\n...",
    todos=[
      { id: "setup", content: "Install dependencies", status: "pending" },
      { id: "auth-pages", content: "Create auth pages", status: "pending" }
    ]
  )
```

**When to Use:**
- Large/ambiguous tasks requiring user approval
- Tasks with multiple valid approaches
- Architectural decisions needed

---

## Parallel Agent Patterns (Cursor 2.4)

### Cursor 2.4 Parallel Capabilities

- **Native Subagents**: Built-in explore, bash, browser run in parallel automatically
- **Custom Subagents**: Define specialized agents that run independently
- **Background Subagents**: Set `is_background: true` for non-blocking execution
- **Multi-Agent Worktrees**: Multiple agents in git worktrees for large features
- **Cloud Agents**: Long-running tasks in cloud environments

### When to Use Each Pattern

| Scenario | Approach |
|----------|----------|
| Codebase exploration | Native `explore` subagent (automatic) |
| Multiple shell commands | Native `bash` subagent (automatic) |
| Browser testing | Native `browser` subagent (automatic) |
| Validate completed work | Custom `verifier` subagent |
| Debug errors | Custom `debugger` subagent |
| Independent features | Parallel custom subagents or worktrees |
| Compare approaches | Multi-agent judging |

### Orchestrator Pattern with Custom Subagents

```
MAIN AGENT (Orchestrator):
├── Plans architecture
├── Delegates to custom subagents
├── Coordinates results
└── Runs /verifier for final check

SUBAGENT: verifier
├── Checks implementation exists
├── Runs tests
├── Validates edge cases
└── Reports pass/fail with details

SUBAGENT: debugger
├── Analyzes error
├── Identifies root cause
├── Suggests fix
└── Returns diagnosis
```

### Spec File Pattern (Still Useful)

For complex multi-agent work, create specs in `.cursor/specs/`:

```markdown
# .cursor/specs/feature-auth.md

## Feature: Authentication System

### Prerequisites
- Database configured with User model
- NextAuth.js installed
- Environment variables set

### Tasks
1. Create `/app/login/page.tsx` - Login form
2. Create `/app/register/page.tsx` - Registration form
3. Create `/app/api/auth/[...nextauth]/route.ts` - NextAuth config
4. Create `/middleware.ts` - Route protection

### Acceptance Criteria
- [ ] User can register with email/password
- [ ] User can login and receive session
- [ ] Protected routes redirect to login

### Verification
After completion, invoke: `/verifier confirm auth feature`
```

### Background Subagent Example

For long-running tasks, use `is_background: true`:

```markdown
---
name: test-runner
description: Test automation expert. Use proactively to run tests and fix failures.
is_background: true
---

You are a test automation expert.

When you see code changes, proactively run appropriate tests.
If tests fail, analyze and report findings.
```

---

## Cursor Hooks Integration

Hooks let you observe, control, and extend the agent loop using custom scripts. They run before or after defined stages of the agent loop.

### Hooks Configuration (`.cursor/hooks.json`)

**CRITICAL**: Use the correct format per [Cursor Hooks docs](https://cursor.com/docs/agent/hooks):

```json
{
  "version": 1,
  "hooks": {
    "stop": [
      { "command": "node .cursor/hooks/grind.js" }
    ],
    "beforeShellExecution": [
      { "command": ".cursor/hooks/audit.sh" }
    ]
  }
}
```

**Format Rules:**
- `version`: Must be `1` (required)
- `hooks`: Object with event names as keys (NOT an array)
- Each event contains an array of hook objects with `command` field

### Hook Events (Agent)

| Event | When | Use Case |
|-------|------|----------|
| `beforeShellExecution` | Before shell command | Block dangerous commands, require approval |
| `afterShellExecution` | After shell command | Audit logs, capture output |
| `beforeMCPExecution` | Before MCP tool call | Gate risky operations |
| `afterMCPExecution` | After MCP tool call | Log tool usage |
| `afterFileEdit` | After file edit | Auto-format, lint, validate |
| `beforeSubmitPrompt` | Before prompt sent | PII scanning, validation |
| `afterAgentResponse` | After agent message | Analytics, logging |
| `afterAgentThought` | After thinking block | Observe reasoning |
| `stop` | Agent loop ends | **RALPH loop**: Continue until goals met (tests pass, build succeeds) |

### Hook Events (Tab/Inline Completions)

| Event | When | Use Case |
|-------|------|----------|
| `beforeTabFileRead` | Before Tab reads file | Redact secrets |
| `afterTabFileEdit` | After Tab edits file | Format Tab edits |

### Example: Audit Hook

```bash
#!/bin/bash
# .cursor/hooks/audit.sh - Log all agent actions

json_input=$(cat)
timestamp=$(date '+%Y-%m-%d %H:%M:%S')
echo "[$timestamp] $json_input" >> /tmp/agent-audit.log
exit 0
```

### Example: Long-Running Agent Loop (RALPH Pattern)

The `stop` hook enables RALPH-style iterative improvement - agent keeps working until verification goals are met.

**Based on**: [Cursor agent best practices - long-running agent loop](https://cursor.com/blog/agent-best-practices#example-long-running-agent-loop)

```javascript
// .cursor/hooks/grind.js - RALPH loop implementation

const input = JSON.parse(await readStdin());
const { status, loop_count = 0 } = input;
const MAX_ITERATIONS = 5;

// Stop if aborted/errored or max iterations reached
if (status !== 'completed' || loop_count >= MAX_ITERATIONS) {
  console.log(JSON.stringify({}));
  process.exit(0);
}

// Check if goals are met (tests pass, build succeeds, etc.)
const goalsMet = checkGoals(); // Run npm test, npm run build, etc.

if (goalsMet) {
  // Goals met - stop the loop
  console.log(JSON.stringify({}));
} else {
  // Goals not met - continue with followup message
  console.log(JSON.stringify({
    followup_message: `Continue working. Iteration ${loop_count + 1}/${MAX_ITERATIONS}. Tests/build still failing.`
  }));
}
```

**How it works:**
1. Agent completes a task
2. `stop` hook runs and checks verification goals (tests, build, lint)
3. If goals met → return `{}` to stop
4. If goals not met → return `{ followup_message: "..." }` to continue
5. Agent receives followup and works on fixing issues
6. Loop continues until goals met or max iterations reached

**Configuration** (`.cursor/grind.json`):
```json
{
  "maxIterations": 5,
  "commands": ["npm test", "npm run build"],
  "stopOnSuccess": true
}
```

### Example: Block Git Commands Hook

```bash
#!/bin/bash
# .cursor/hooks/block-git.sh - Require gh CLI instead of git

input=$(cat)
command=$(echo "$input" | jq -r '.command // empty')

if [[ "$command" =~ ^git[[:space:]] ]]; then
  cat << EOF
{
  "permission": "deny",
  "user_message": "Git command blocked. Use gh CLI instead.",
  "agent_message": "The git command was blocked. Use gh tool for GitHub operations."
}
EOF
else
  echo '{"permission": "allow"}'
fi
```

### Hook Input/Output Schema

**Input (all hooks receive):**
```json
{
  "conversation_id": "string",
  "generation_id": "string", 
  "model": "string",
  "hook_event_name": "string",
  "cursor_version": "string",
  "workspace_roots": ["<path>"]
}
```

**Output (permission hooks):**
```json
{
  "permission": "allow" | "deny" | "ask",
  "user_message": "<shown to user>",
  "agent_message": "<sent to agent>"
}
```

**Output (stop hook - for RALPH loop):**
```json
{}  // Empty object = stop the loop

// OR continue with:
{
  "followup_message": "Continue working on the task. Fix the failing tests."
}
```

---

## Context Compaction for Long-Running Tasks

Opus 4.6 introduces **compaction** — the ability to summarize its own context to sustain longer tasks. Apply this principle in agentic workflows:

### When to Compact

- After completing each EPIC in a multi-EPIC task
- When context is getting large (many files read, many tool calls)
- Before starting a new phase of work

### How to Compact

```
<think>
[COMPACTION — End of EPIC N]

Essential state to carry forward:
- Project: [stack, conventions]
- Completed: [what's done and verified]
- Current: [what I'm working on next]
- Decisions: [key choices made and why]
- Known issues: [anything to watch for]

Can release from active context:
- Detailed file contents already processed
- Intermediate debugging steps
- Exploration results that didn't lead anywhere
</think>
```

### Compaction + Subagents

For exhaustive tasks, use subagents to isolate context-heavy work:
- Exploration subagent reads and analyzes files (its context is isolated)
- Main agent receives a summary, not the raw data
- This naturally compacts context without explicit summarization

---

## Cursor 2.4 Agent Skills

Agent Skills are portable, version-controlled packages that teach agents domain-specific tasks. Skills are the preferred way to package specialized knowledge in Cursor 2.4.

### Skills vs Rules

| Feature | Rules (`.cursor/rules/`) | Skills (`.cursor/skills/`) |
|---------|--------------------------|----------------------------|
| Activation | `alwaysApply: true` or glob patterns | Auto-discovery or `/skill-name` |
| Format | Single `.mdc` file | Folder with `SKILL.md` + optional scripts |
| Executable | No | Yes - can include scripts |
| Progressive loading | No | Yes - loads resources on-demand |
| Best for | Always-on conventions, file-type patterns | Domain knowledge, procedures, how-tos |

### Skill Directory Structure

```
.cursor/skills/
└── deploy-app/
    ├── SKILL.md           # Required - main instructions
    ├── scripts/           # Optional - executable code
    │   ├── deploy.sh
    │   └── validate.py
    ├── references/        # Optional - detailed docs (loaded on-demand)
    │   └── REFERENCE.md
    └── assets/            # Optional - templates, configs
        └── config-template.json
```

### SKILL.md Format

```markdown
---
name: deploy-app
description: Deploy the application to staging or production. Use when deploying code or when user mentions deployment.
---

# Deploy App

Deploy the application using the provided scripts.

## Usage

Run the deployment script: `scripts/deploy.sh <environment>`

## Pre-deployment Validation

Before deploying, run: `python scripts/validate.py`
```

**Frontmatter Fields:**

| Field | Required | Description |
|-------|----------|-------------|
| `name` | Yes | Skill identifier. Must match folder name. |
| `description` | Yes | When to use. Agent reads this to determine relevance. |
| `license` | No | License name or file reference. |
| `disable-model-invocation` | No | If `true`, only invoked via `/skill-name`. |

### Invoking Skills

**Automatic**: Agent discovers and applies based on context + description.

**Explicit**: Type `/skill-name` in chat:
```
> /deploy-app deploy to staging
> /migrate-to-skills convert my rules
```

### Migration: Rules to Skills

Cursor 2.4 includes `/migrate-to-skills` to convert dynamic rules:

```
> /migrate-to-skills
```

This converts:
- **Dynamic rules** (`alwaysApply: false`, no globs) → Standard skills
- **Slash commands** → Skills with `disable-model-invocation: true`

**What NOT to migrate:**
- Rules with `alwaysApply: true` (keep as rules)
- Rules with `globs` patterns (keep as rules - skills don't have glob triggers)

### Recommended Organization

```
.cursor/
├── rules/                    # Keep these as rules
│   ├── minimax-m2-core.mdc          # alwaysApply: true
│   ├── cursor-agent-orchestration.mdc  # alwaysApply: true
│   ├── web-development.mdc          # globs: ["*.ts", "*.tsx"]
│   └── python-development.mdc       # globs: ["*.py"]
│
├── skills/                   # Domain knowledge, procedures
│   ├── deploy-production/
│   │   └── SKILL.md
│   ├── database-migration/
│   │   └── SKILL.md
│   └── security-audit/
│       └── SKILL.md
│
└── agents/                   # Custom subagents
    ├── verifier.md
    └── debugger.md
```

### Anti-Hallucination: Clear Descriptions

**Good** - Specific trigger conditions:
```yaml
description: "Deploy to production. Use when user mentions 'deploy', 'release', 'push to prod', or 'go live'."
```

**Bad** - Vague, will trigger inappropriately:
```yaml
description: "Helps with general deployment tasks"
```

---

## Summary: Opus 4.6 Max + Cursor 2.4 Workflow

### Before Starting Any Task

```
1. CALIBRATE EFFORT
   → Instant / Light / Deep / Exhaustive?
   → Match workflow depth to complexity

2. CHECK DATE (for version searches)
   → Extract current date from context
   → Use concrete values, never placeholders

3. FOR DEEP/EXHAUSTIVE TASKS
   → Create EPIC todos (Exhaustive only)
   → Investigate codebase patterns first
   → Plan with tradeoffs stated

4. FOR EACH FILE/CHANGE
   → Implement
   → Lint check (ReadLints on edited file)
   → Self-review (Light+): What would break?
   → Mark complete only after verified

5. ON REPEATED ERRORS (3-4+)
   → Stop trying same fix
   → Web search for solution
   → Apply community solution

6. AFTER EPIC/FEATURE COMPLETE
   → Run /verifier to validate
   → Integration test
   → Compact context before next phase
```

### Quality Gates

```
□ Effort calibrated to task complexity
□ Adversarial self-review performed (Light+)
□ Date included in version searches (for NEW packages)
□ No template placeholders in searches
□ Each file verified after creation
□ Web search triggered after 3-4 repeated errors
□ Context compacted between phases (long tasks)
□ Honest about uncertainty
```

### Quick Reference: Subagents vs Skills vs Rules

| Need | Solution |
|------|----------|
| Always-on conventions | Rules with `alwaysApply: true` |
| File-type patterns | Rules with `globs` |
| Domain knowledge | Skills in `.cursor/skills/` |
| Specialized agents | Custom subagents in `.cursor/agents/` |
| Validation | `/verifier` subagent |
| Debugging | `/debugger` subagent |
